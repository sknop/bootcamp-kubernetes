apiVersion: platform.confluent.io/v1beta1
kind: Zookeeper
metadata:
  name: zookeeper
  namespace: confluent
spec:
  metrics:
    prometheus:
      whitelist:
        - org.apache.ZooKeeperService:name3=Connections,*
        - org.apache.ZooKeeperService:name3=InMemoryDataTree,*
        - org.apache.ZooKeeperService:name0=*,name1=replica*,name2=*
        - org.apache.ZooKeeperService:name0=*,name1=replica*
        - org.apache.ZooKeeperService:name0=*
        # If you are running a Standalone Zookeeper, the whitelist objects below would help.
        # If the zookeeper has a quorum, no need to worry about anything else.
        - org.apache.ZooKeeperService:name1=InMemoryDataTree,name0=*
        - org.apache.ZooKeeperService:name0=*,name1=Connections,name2=*,name3=*
      rules:
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*,name3=Connections,name1=*,name2=*,name4=*,name5=*
        - pattern: "org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+), name2=(\\w+), name3=Connections, name4=(.+), name5=(.+)><>([^:]+)"
          name: zookeeper_connections_$6
          labels:
            server_name: "$1"
            server_id: $2
            client_address: "$4"
            connection_id: "$5"
            member_type: "$3"
        - pattern: "org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+), name2=(\\w+)><>(\\w+): (\\d+)"
          name: zookeeper_$4
          labels:
            server_name: "$1"
            server_id: $2
            member_type: "$3"
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*,name3=InMemoryDataTree
        - pattern: "org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+), name2=(\\w+), name3=InMemoryDataTree><>(WatchCount|NodeCount): (\\d+)"
          name: zookeeper_inmemorydatatree_$4
          type: GAUGE
          labels:
            server_name: "$1"
            server_id: $2
            member_type: "$3"
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*,name1=replica*
        - pattern: "org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+)><>(.+): (.+)"
          name: zookeeper_status
          type: UNTYPED
          value: "1"
          labels:
            server_name: "$1"
            server_id: $2
            $3: $4
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*
        - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+)><>(QuorumSize): (\\d+)"
          name: zookeeper_status_$2
          type: GAUGE
          labels:
            server_id: $1
        # ###########################################################################
        # ###########################################################################
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*,name1=InMemoryDataTree
        - pattern: "org.apache.ZooKeeperService<name0=(.+), name1=InMemoryDataTree><>(WatchCount|NodeCount): (\\d+)"
          name: zookeeper_inmemorydatatree_$2
          type: GAUGE
          labels:
            server_name: $1
            server_id: "1"
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*,name1=Connections,name2=*,name3=*
        - pattern: "org.apache.ZooKeeperService<name0=(.+), name1=Connections, name2=(.+), name3=(.+)><>([^:]+)"
          name: zookeeper_connections_$4
          labels:
            server_name: "$1"
            client_address: "$2"
            connection_id: "$3"
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*
        - pattern: "org.apache.ZooKeeperService<name0=(.+)><>(StartTime|ClientPort|SecureClientAddress|Version|SecureClientPort): (.+)"
          name: zookeeper_$2
          value: "1"
          labels:
            server_name: "$1"
            $2: "$3"
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*
        - pattern: "org.apache.ZooKeeperService<name0=(.+)><>(.+): (.+)"
          name: zookeeper_$2
          type: GAUGE

---
apiVersion: platform.confluent.io/v1beta1
kind: Kafka
metadata:
  name: kafka
spec:
  metrics:
    prometheus:
      blacklist:
        - "kafka.consumer:type=*,id=*"
        - "kafka.consumer:type=*,client-id=*"
        - "kafka.consumer:type=*,client-id=*,node-id=*"
        - "kafka.producer:type=*,id=*"
        - "kafka.producer:type=*,client-id=*"
        - "kafka.producer:type=*,client-id=*,node-id=*"
        - "kafka.*:type=kafka-metrics-count,*"
        # This will ignore the admin client metrics from Kafka Brokers and will blacklist certain metrics
        # that do not make sense for ingestion.
        # "kafka.admin.client:type=*, node-id=*, client-id=*"
        # "kafka.admin.client:type=*, client-id=*"
        # "kafka.admin.client:type=*, id=*"
        - "kafka.admin.client:*"
        - "kafka.server:type=*,cipher=*,protocol=*,listener=*,networkProcessor=*"
        - "kafka.server:type=*"
      rules:
        # This is by far the biggest contributor to the number of sheer metrics being produced.
        # Always keep it on the top for the case of probability when so many metrics will hit the first condition and exit.
        # "kafka.cluster:type=*, name=*, topic=*, partition=*"
        # "kafka.log:type=*,name=*, topic=*, partition=*"
        - pattern: kafka.(\w+)<type=(.+), name=(.+), topic=(.+), partition=(.+)><>Value
          name: kafka_$1_$2_$3
          type: GAUGE
          labels:
            topic: "$4"
            partition: "$5"
        # "kafka.server:type=*,name=*, client-id=*, topic=*, partition=*"
        - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
          name: kafka_server_$1_$2
          type: GAUGE
          labels:
            clientId: "$3"
            topic: "$4"
            partition: "$5"
        - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
          name: kafka_server_$1_$2
          type: GAUGE
          labels:
            clientId: "$3"
            broker: "$4:$5"
        # "kafka.network:type=*, name=*, request=*, error=*"
        # "kafka.network:type=*, name=*, request=*, version=*"
        - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>(Count|Value)
          name: kafka_$1_$2_$3
          labels:
            "$4": "$5"
            "$6": "$7"
        - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)><>(\d+)thPercentile
          name: kafka_$1_$2_$3
          type: GAUGE
          labels:
            "$4": "$5"
            "$6": "$7"
            quantile: "0.$8"
        # "kafka.rest:type=*, topic=*, partition=*, client-id=*"
        # "kafka.rest:type=*, cipher=*, protocol=*, client-id=*"
        - pattern: kafka.(\w+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>Value
          name: kafka_$1_$2
          labels:
            "$3": "$4"
            "$5": "$6"
            "$7": "$8"
        # Count and Value
        # "kafka.server:type=*, name=*, topic=*"
        # "kafka.server:type=*, name=*, clientId=*"
        # "kafka.server:type=*, name=*, delayedOperation=*"
        # "kafka.server:type=*, name=*, fetcherType=*"
        # "kafka.network:type=*, name=*, networkProcessor=*"
        # "kafka.network:type=*, name=*, processor=*"
        # "kafka.network:type=*, name=*, request=*"
        # "kafka.network:type=*, name=*, listener=*"
        # "kafka.log:type=*, name=*, logDirectory=*"
        # "kafka.log:type=*, name=*, op=*"
        # "kafka.rest:type=*, node-id=*, client-id=*"
        - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>(Count|Value)
          name: kafka_$1_$2_$3
          labels:
            "$4": "$5"
        # "kafka.consumer:type=*, topic=*, client-id=*"
        # "kafka.producer:type=*, topic=*, client-id=*"
        # "kafka.rest:type=*, topic=*, client-id=*"
        # "kafka.server:type=*, broker-id=*, fetcher-id=*"
        # "kafka.server:type=*, listener=*, networkProcessor=*"
        - pattern: kafka.(\w+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(Count|Value)
          name: kafka_$1_$2
          labels:
            "$3": "$4"
            "$5": "$6"
        # "kafka.network:type=*, name=*"
        # "kafka.server:type=*, name=*"
        # "kafka.controller:type=*, name=*"
        # "kafka.databalancer:type=*, name=*"
        # "kafka.log:type=*, name=*"
        # "kafka.utils:type=*, name=*"
        - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(Count|Value)
          name: kafka_$1_$2_$3
        # "kafka.producer:type=*, client-id=*"
        # "kafka.producer:type=*, id=*"
        # "kafka.rest:type=*, client-id=*"
        # "kafka.rest:type=*, http-status-code=*"
        # "kafka.server:type=*, BrokerId=*"
        # "kafka.server:type=*, listener=*"
        # "kafka.server:type=*, id=*"
        - pattern: kafka.(\w+)<type=(.+), (.+)=(.+)><>Value
          name: kafka_$1_$2
          labels:
            "$3": "$4"

        - pattern: kafka.server<type=KafkaRequestHandlerPool, name=RequestHandlerAvgIdlePercent><>OneMinuteRate
          name: kafka_server_kafkarequesthandlerpool_requesthandleravgidlepercent_total
          type: GAUGE
        # "kafka.server:type=*, listener=*, networkProcessor=*, clientSoftwareName=*, clientSoftwareVersion=*"
        - pattern: kafka.server<type=socket-server-metrics, clientSoftwareName=(.+), clientSoftwareVersion=(.+), listener=(.+), networkProcessor=(.+)><>connections
          name: kafka_server_socketservermetrics_connections
          type: GAUGE
          labels:
            client_software_name: "$1"
            client_software_version: "$2"
            listener: "$3"
            network_processor: "$4"
        - pattern: "kafka.server<type=socket-server-metrics, listener=(.+), networkProcessor=(.+)><>(.+):"
          name: kafka_server_socketservermetrics_$3
          type: GAUGE
          labels:
            listener: "$1"
            network_processor: "$2"
        # "kafka.coordinator.group:type=*, name=*"
        # "kafka.coordinator.transaction:type=*, name=*"
        - pattern: kafka.coordinator.(\w+)<type=(.+), name=(.+)><>(Count|Value)
          name: kafka_coordinator_$1_$2_$3
        # Percentile
        - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*)><>(\d+)thPercentile
          name: kafka_$1_$2_$3
          type: GAUGE
          labels:
            "$4": "$5"
            quantile: "0.$6"
        - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\d+)thPercentile
          name: kafka_$1_$2_$3
          type: GAUGE
          labels:
            quantile: "0.$4"
        # Additional Rules for Confluent Server Metrics
        # 'confluent.metadata:type=*, name=*, topic=*, partition=*'
        - pattern: confluent.(\w+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>Value
          name: confluent_$1_$2
          type: GAUGE
          labels:
            "$3": "$4"
            "$5": "$6"
            "$7": "$8"
        # 'confluent.metadata.service:type=*, node-id=*, client-id=*'
        - pattern: confluent.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>Value
          name: confluent_$1_$2
          type: GAUGE
          labels:
            "$3": "$4"
            "$5": "$6"
        # 'confluent.metadata.service:type=*, client-id=*'
        # 'confluent.metadata.service:type=*, id=*'
        # 'confluent.metadata:type=*, name=*'
        # 'confluent.license:type=*, name=*'
        - pattern: confluent.(.+)<type=(.+), (.+)=(.+)><>Value
          name: confluent_$1_$2
          type: GAUGE
          labels:
            "$3": "$4"

        # Quotas
        - pattern : 'kafka.server<type=(Produce|Fetch|Request), user=(.+), client-id=(.+)><>(.+):'
          name: kafka_server_$1_$4
          type: GAUGE
          labels:
            user: "$2"
            client-id: "$3"

        - pattern : 'kafka.server<type=(Produce|Fetch|Request), user=(.+)><>(.+):'
          name: kafka_server_$1_$3
          type: GAUGE
          labels:
            user: "$2"

        - pattern : 'kafka.server<type=(Produce|Fetch|Request), client-id=(.+)><>(.+):'
          name: kafka_server_$1_$3
          type: GAUGE
          labels:
            client-id: "$2"
---
apiVersion: platform.confluent.io/v1beta1
kind: Connect
metadata:
  name: connect
  namespace: confluent
spec:
  metrics:
    prometheus:
      whitelist:
        # Engine Application Versioning Info
        - "kafka.connect:type=app-info,client-id=*"
        # Connect Worker Rebalancing info
        - "kafka.connect:type=connect-worker-rebalance-metrics"
        # Connect Co-ordinator Info
        - "kafka.connect:type=connect-coordinator-metrics,*"
        - "kafka.connect:type=connect-metrics,*"
        # Worker level metrics for the aggregate as well as per connector level
        - "kafka.connect:type=connect-worker-metrics"
        - "kafka.connect:type=connect-worker-metrics,*"
        # Engine Connector Versioning Info
        - "kafka.connect:type=connector-metrics,*"
        # Task level metrics for every connector running in the current node.
        - "kafka.connect:type=*-task-metrics,*"
        - "kafka.connect:type=task-error-metrics,*"
        #  Confluent Replicator JMX Stats
        - "confluent.replicator:type=confluent-replicator-task-metrics,*"
        # The two lines below are used to pull the Kafka Client Producer & consumer metrics from Connect Workers.
        # If you care about Producer/Consumer metrics for Connect, please uncomment 2 lines below.
        # Please note that this increases the scrape duration by about 1-2 seconds as it needs to parse a lot of data.
        - "kafka.consumer:*"
        - "kafka.producer:*"
      blacklist:
        # This will ignore the admin client metrics from KSQL server and will blacklist certain metrics
        # that do not make sense for ingestion.
        - "kafka.admin.client:*"
        - "kafka.consumer:type=*,id=*"
        - "kafka.producer:type=*,id=*"
        - "kafka.producer:client-id=confluent.monitoring*,*"
        - "kafka.*:type=kafka-metrics-count,*"
      rules:
        # "kafka.schema.registry:type=app-info,id=*"
        - pattern: "kafka.connect<type=app-info, client-id=(.+)><>(.+): (.+)"
          name: "kafka_connect_app_info"
          value: "1"
          labels:
            client-id: "$1"
            $2: "$3"
          type: UNTYPED
        # kafka.connect:type=connect-worker-rebalance-metrics
        - pattern: "kafka.connect<type=connect-worker-rebalance-metrics><>([^:]+)"
          name: "kafka_connect_connect_worker_rebalance_metrics_$1"
        # kafka.connect:type=connect-coordinator-metrics,client-id=*
        # kafka.connect:type=connect-metrics,client-id=*
        - pattern: "kafka.connect<type=(.+), client-id=(.+)><>([^:]+)"
          name: kafka_connect_$1_$3
          labels:
            client_id: $2
        # kafka.connect:type=connect-worker-metrics
        - pattern: "kafka.connect<type=connect-worker-metrics><>([^:]+)"
          name: kafka_connect_connect_worker_metrics_$1
          labels:
            connector: "aggregate"
        # kafka.connect:type=connect-worker-metrics,connector=*
        - pattern: "kafka.connect<type=connect-worker-metrics, connector=(.+)><>([^:]+)"
          name: kafka_connect_connect_worker_metrics_$2
          labels:
            connector: $1
        # kafka.connect:type=connector-metrics,connector=*
        - pattern: "kafka.connect<type=connector-metrics, connector=(.+)><>(.+): (.+)"
          value: "1"
          name: kafka_connect_connector_metrics
          labels:
            connector: $1
            $2: $3
          type: UNTYPED
        # kafka.connect:type=*-task-metrics,*
        # kafka.connect:type=source-task-metrics,connector=*,task=*
        # kafka.connect:type=sink-task-metrics,connector=*,task=*
        # kafka.connect:type=connector-task-metrics,connector=*,task=*
        - pattern: "kafka.connect<type=(.+)-task-metrics, connector=(.+), task=(\\d+)><>(.+): (.+)"
          name: kafka_connect_$1_task_metrics_$4
          labels:
            connector: "$2"
            task: "$3"
        # kafka.connect:type=task-error-metrics,*
        # kafka.connect:type=task-error-metrics,connector=*,task=*
        - pattern: "kafka.connect<type=task-error-metrics, connector=(.+), task=(\\d+)><>([^:]+)"
          name: kafka_connect_task_error_metrics_$3
          labels:
            connector: "$1"
            task: "$2"
        # confluent.replicator:type=confluent-replicator-task-metrics,* : confluent-replicator-task-topic-partition-*: Number Values
        - pattern: "confluent.replicator<type=confluent-replicator-task-metrics, confluent-replicator-(.*)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+)><>confluent-replicator-task-topic-partition-(.*): (.*)"
          name: confluent_replicator_task_metrics_$9
          labels:
            $1: "$2"
            $3: "$4"
            $5: "$6"
            $7: "$8"
        # confluent.replicator:type=confluent-replicator-task-metrics,* : Strings
        - pattern: "confluent.replicator<type=confluent-replicator-task-metrics, confluent-replicator-(.*)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+)><>(confluent-replicator-destination-cluster|confluent-replicator-source-cluster|confluent-replicator-destination-topic-name): (.*)"
          name: confluent_replicator_task_metrics_info
          value: "1"
          labels:
            $1: "$2"
            $3: "$4"
            $5: "$6"
            $7: "$8"
            $9: "$10"
        # "kafka.consumer:type=app-info,client-id=*"
        # "kafka.producer:type=app-info,client-id=*"
        - pattern: "kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)"
          value: "1"
          name: kafka_$1_app_info
          labels:
            client_type: $1
            client_id: $2
            $3: $4
          type: UNTYPED
        # "kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*"
        # "kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*"
        # "kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$9
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
            $7: "$8"
        # "kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*"
        # "kafka.producer:type=producer-node-metrics,client-id=*, node-id=*"
        # "kafka.producer:type=producer-topic-metrics,client-id=*, topic=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$7
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*"
        # "kafka.consumer:type=consumer-metrics,client-id=*"
        # "kafka.producer:type=producer-metrics,client-id=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$5
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
        - pattern: "kafka.(.+)<type=(.+)><>(.+):"
          name: kafka_$1_$2_$3
          labels:
            client_type: $1

---
apiVersion: platform.confluent.io/v1beta1
kind: KsqlDB
metadata:
  name: ksqldb
  namespace: confluent
spec:
  metrics:
    prometheus:
      whitelist:
        - "io.confluent.ksql.metrics:*"
        - "kafka.consumer:*"
        - "kafka.producer:*"
        - "kafka.streams:*"
      blacklist:
        - "kafka.streams:type=kafka-metrics-count"
        - "kafka.admin.client:*"
        - "kafka.consumer:type=*,id=*"
        - "kafka.consumer:type=*,client-id=*"
        - "kafka.consumer:type=*,client-id=*,node-id=*"
        - "kafka.producer:type=*,id=*"
        - "kafka.producer:type=*,client-id=*"
        - "kafka.producer:type=*,client-id=*,node-id=*"
        - "kafka.streams:type=stream-processor-node-metrics,thread-id=*,task-id=*,processor-node-id=*"
        - "kafka.*:type=kafka-metrics-count,*"
      rules:
        # "io.confluent.ksql.metrics:type=producer-metrics,key=*,id=*"
        # "io.confluent.ksql.metrics:type=consumer-metrics,key=*,id=*"
        - pattern: io.confluent.ksql.metrics<type=(.+), key=(.+), id=(.+)><>([^:]+)
          name: ksql_$1_$4
          labels:
            key: "$2"
            id: "$3"
        # "io.confluent.ksql.metrics:type=_confluent-ksql-<cluster-id>ksql-engine-query-stats"
        # The below statement parses KSQL Cluster Name and adds a new label so that per cluster data is searchable.
        - pattern: io.confluent.ksql.metrics<type=_confluent-ksql-(.+)ksql-engine-query-stats><>([^:]+)
          name: "ksql_ksql_engine_query_stats_$2"
          labels:
            ksql_cluster: $1
        # "io.confluent.ksql.metrics:type=ksql-queries,status=_confluent-ksql-<cluser-id>_query_<query>
        # The below statement parses KSQL query specific status
        - pattern: "io.confluent.ksql.metrics<type=(.+), status=_confluent-ksql-(.+)query_(.+)><>(.+): (.+)"
          value: "1"
          name: ksql_ksql_metrics_$1_$4
          labels:
            ksql_query: $3
            ksql_cluster: $2
            $4: $5
        # kafka.streams:type=stream-processor-node-metrics,processor-node-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-record-cache-metrics,record-cache-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
        - pattern: "kafka.streams<type=(.+), thread-id=(.+), task-id=(.+), (.+)=(.+)><>(.+):"
          name: kafka_streams_$1_$6
          type: GAUGE
          labels:
            thread_id: "$2"
            task_id: "$3"
            $4: "$5"
        # kafka.streams:type=stream-task-metrics,task-id=*,thread-id=*
        - pattern: "kafka.streams<type=(.+), thread-id=(.+), task-id=(.+)><>(.+):"
          name: kafka_streams_$1_$4
          type: GAUGE
          labels:
            thread_id: "$2"
            task_id: "$3"
        # kafka.streams:type=stream-metrics,client-id=*
        - pattern: "kafka.streams<type=stream-metrics, (.+)=(.+)><>(state|alive-stream-threads|commit-id|version|application-id): (.+)"
          name: kafka_streams_stream_metrics
          value: "1"
          type: UNTYPED
          labels:
            $1: "$2"
            $3: "$4"
        # kafka.streams:type=stream-thread-metrics,thread-id=*
        - pattern: "kafka.streams<type=(.+), (.+)=(.+)><>([^:]+)"
          name: kafka_streams_$1_$4
          type: GAUGE
          labels:
            $2: "$3"
        # "kafka.consumer:type=app-info,client-id=*"
        # "kafka.producer:type=app-info,client-id=*"
        - pattern: "kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)"
          value: "1"
          name: kafka_$1_app_info
          labels:
            client_type: $1
            client_id: $2
            $3: $4
          type: UNTYPED
        # "kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*"
        # "kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*"
        # "kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$9
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
            $7: "$8"
        # "kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*"
        # "kafka.producer:type=producer-node-metrics,client-id=*, node-id=*"
        # "kafka.producer:type=producer-topic-metrics,client-id=*, topic=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$7
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*"
        # "kafka.consumer:type=consumer-metrics,client-id=*"
        # "kafka.producer:type=producer-metrics,client-id=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$5
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
        - pattern: "kafka.(.+)<type=(.+)><>(.+):"
          name: kafka_$1_$2_$3
          labels:
            client_type: $1e
---
apiVersion: platform.confluent.io/v1beta1
kind: SchemaRegistry
metadata:
  name: schemaregistry
  namespace: confluent
spec:
  metrics:
    prometheus:
      whitelist:
        - kafka.schema.registry:type=jetty-metrics
        - kafka.schema.registry:type=jersey-metrics
        - kafka.schema.registry:type=app-info,id=*
        - kafka.schema.registry:type=registered-count
        - kafka.schema.registry:type=json-schema*
        - kafka.schema.registry:type=protobuf-schemas*
        - kafka.schema.registry:type=avro-schemas*
        - kafka.schema.registry:type=kafka.schema.registry-metrics,client-id=*
        - kafka.schema.registry:type=kafka.schema.registry-coordinator-metrics,client-id=*
        # The two lines below are used to pull the Kafka Client Producer & consumer metrics from SR Client.
        # If you care about Producer/Consumer metrics for SR, please uncomment 2 lines below.
        # Please note that this increases the scrape duration to about 1 second as it needs to parse a lot of data.
        - "kafka.consumer:*"
        - "kafka.producer:*"
      blacklist:
        # This will ignore the admin client metrics from SR server and will blacklist certain metrics
        # that do not make sense for ingestion.
        - "kafka.producer:type=app-info,client-id=*"
        - "kafka.consumer:type=app-info,client-id=*"
        - "kafka.admin.client:*"
        - "kafka.consumer:type=*,id=*"
        - "kafka.producer:type=*,id=*"
        # - "kafka.producer:client-id=confluent.monitoring*,*"
        # - "kafka.producer:client-id=confluent-license*,*"
        - "kafka.*:type=kafka-metrics-count,*"
      rules:
        # "kafka.schema.registry:type=jetty-metrics"
        - pattern: "kafka.schema.registry<type=jetty-metrics>([^:]+):"
          name: "kafka_schema_registry_jetty_metrics_$1"
        # "kafka.schema.registry:type=jersey-metrics"
        - pattern: "kafka.schema.registry<type=jersey-metrics>([^:]+):"
          name: "kafka_schema_registry_jersey_metrics_$1"
        # "kafka.schema.registry:type=app-info,id=*"
        - pattern: "kafka.schema.registry<type=app-info, id=(.+)><>(.+): (.+)"
          name: "kafka_schema_registry_app_info"
          value: "1"
          labels:
            client-id: "$1"
            $2: "$3"
          type: UNTYPED
        # "kafka.schema.registry:type=registered-count"
        - pattern: "kafka.schema.registry<type=registered-count>([^:]+):"
          name: "kafka_schema_registry_registered_count"
        # "kafka.schema.registry:type=json-schemas-created"
        # "kafka.schema.registry:type=json-schemas-deleted"
        # "kafka.schema.registry:type=protobuf-schemas-created"
        # "kafka.schema.registry:type=protobuf-schemas-deleted"
        # "kafka.schema.registry:type=avro-schemas-created"
        # "kafka.schema.registry:type=avro-schemas-deleted"
        - pattern: "kafka.schema.registry<type=(\\w+)-schemas-(\\w+)>([^:]+):"
          name: "kafka_schema_registry_schemas_$2"
          labels:
            schema_type: $1
        # kafka.schema.registry:type=kafka.schema.registry-metrics,client-id=*
        # kafka.schema.registry:type=kafka.schema.registry-coordinator-metrics,client-id=*
        - pattern: "kafka.schema.registry<type=(.+), client-id=(.+)><>([^:]+):"
          name: "kafka_schema_registry_$1_$3"
          labels:
            client_id: $2
        # "kafka.consumer:type=app-info,client-id=*"
        # "kafka.producer:type=app-info,client-id=*"
        - pattern: "kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)"
          value: "1"
          name: kafka_$1_app_info
          labels:
            client_type: $1
            client_id: $2
            $3: $4
          type: UNTYPED
        # "kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*"
        # "kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*"
        # "kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$9
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
            $7: "$8"
        # "kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*"
        # "kafka.producer:type=producer-node-metrics,client-id=*, node-id=*"
        # "kafka.producer:type=producer-topic-metrics,client-id=*, topic=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$7
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*"
        # "kafka.consumer:type=consumer-metrics,client-id=*"
        # "kafka.producer:type=producer-metrics,client-id=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$5
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
        - pattern: "kafka.(.+)<type=(.+)><>(.+):"
          name: kafka_$1_$2_$3
          labels:
            client_type: $1
---
apiVersion: platform.confluent.io/v1beta1
kind: ControlCenter
metadata:
  name: controlcenter
  namespace: confluent
spec:
  metrics:
    prometheus:
      whitelist:
        - kafka.streams:*
        # The two lines below are used to pull the Kafka Client Producer & consumer metrics from Kafka Streams Client.
        # If you care about Producer/Consumer metrics for Kafka Streams, please uncomment 2 lines below.
        # Please note that this increases the scrape duration by about 1-2 seconds as it needs to parse a lot of data.
        - "kafka.consumer:*"
        - "kafka.producer:*"
      blacklist:
        - "kafka.streams:type=kafka-metrics-count"
        - "kafka.admin.client:*"
        - "kafka.consumer:type=*,id=*"
        - "kafka.producer:type=*,id=*"
        - "kafka.*:type=kafka-metrics-count,*"
      rules:
        # kafka.streams:type=stream-processor-node-metrics,processor-node-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-record-cache-metrics,record-cache-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
        - pattern: "kafka.streams<type=(.+), thread-id=(.+), task-id=(.+), (.+)=(.+)><>(.+):"
          name: kafka_streams_$1_$6
          type: GAUGE
          labels:
            thread_id: "$2"
            task_id: "$3"
            $4: "$5"
        # kafka.streams:type=stream-task-metrics,task-id=*,thread-id=*
        - pattern: "kafka.streams<type=(.+), thread-id=(.+), task-id=(.+)><>(.+):"
          name: kafka_streams_$1_$4
          type: GAUGE
          labels:
            thread_id: "$2"
            task_id: "$3"
        # kafka.streams:type=stream-metrics,client-id=*
        - pattern: "kafka.streams<type=stream-metrics, (.+)=(.+)><>(state|alive-stream-threads|commit-id|version|application-id): (.+)"
          name: kafka_streams_stream_metrics
          value: "1"
          type: UNTYPED
          labels:
            $1: "$2"
            $3: "$4"
        # kafka.streams:type=stream-thread-metrics,thread-id=*
        - pattern: "kafka.streams<type=(.+), (.+)=(.+)><>([^:]+)"
          name: kafka_streams_$1_$4
          type: GAUGE
          labels:
            $2: "$3"
        # "kafka.consumer:type=app-info,client-id=*"
        # "kafka.producer:type=app-info,client-id=*"
        - pattern: "kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)"
          value: "1"
          name: kafka_$1_app_info
          labels:
            client_type: $1
            client_id: $2
            $3: $4
          type: UNTYPED
        # "kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*"
        # "kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*"
        # "kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$9
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
            $7: "$8"
        # "kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*"
        # "kafka.producer:type=producer-node-metrics,client-id=*, node-id=*"
        # "kafka.producer:type=producer-topic-metrics,client-id=*, topic=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$7
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
            $5: "$6"
        # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*"
        # "kafka.consumer:type=consumer-metrics,client-id=*"
        # "kafka.producer:type=producer-metrics,client-id=*"
        - pattern: "kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):"
          name: kafka_$1_$2_$5
          type: GAUGE
          labels:
            client_type: $1
            $3: "$4"
        - pattern: "kafka.(.+)<type=(.+)><>(.+):"
          name: kafka_$1_$2_$3
          labels:
            client_type: $1

